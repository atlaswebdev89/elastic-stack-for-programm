name: ${NAME_PROJECT}
networks:
  elastic:
    driver: bridge

volumes:
  elastic2-data:
  elastic1-data:
  elastic3-data:
  elastic4-data:

services:
  # Для балансировки запросов к logstash
  web-proxy-logstash:
    image: nginx:latest
    container_name: nginx-proxy-logstash
    hostname: nginx-proxy-logstash
    restart: unless-stopped
    ports:
      - ${PROXY_NGINX_SYSLOG}:514
      - ${PROXY_NGINX_SYSLOG}:514/udp
      - ${PROXY_NGINX_LOGSTASH}:5146
      - ${PROXY_NGINX_LOGSTASH}:5146/udp
      - ${PROXY_NGINX_LOGSTASH_BEATS}:5147
      - ${PROXY_NGINX_ELASTIC}:9200
      - ${PROXY_NGINX_NETFLOW}:2055/udp
    volumes:
      - ./nginx/nginx-logstash/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./nginx/nginx-logstash/stream-proxy.conf:/etc/nginx/stream-proxy/stream-proxy.conf:ro
      - ./nginx/nginx-logstash/http-proxy.conf:/etc/nginx/http-proxy/http-proxy.conf:ro
      # Без этого не работает. Возможно в будущем надо будет пересоздать образ. Создать Dockerfile с этими файлами
      # чтоб не засорять docker-compose
      - ./logs/nginx/logstash/stream/logstash-connect.log:/var/log/nginx/logstash/logstash-connect.log
      - ./logs/nginx/logstash/stream/logstash-error.log:/var/log/nginx/logstash/logstash-error.log
      - ./logs/nginx/logstash/stream/beats-error.log:/var/log/nginx/logstash/beats-error.log
      - ./logs/nginx/logstash/http/access-direct-elastic.log:/var/log/nginx/direct-elastic/access-direct-elastic.log
      - ./logs/nginx/logstash/http/error-direct-elastic.log:/var/log/nginx/direct-elastic/error-direct-elastic.log
      
    networks:
      - elastic
    depends_on:
      - elastic-logstash-node-1
      - elastic-logstash-node-2
      - elastic-node-coordination-1
      - elastic-node-coordination-2
    healthcheck:
      test: nginx -t 2>/dev/null || exit 1
      interval: 5s
      timeout: 5s
      retries: 10
    logging:
      driver: "json-file"
      options:
        max-size: "100m" # Максимальный размер файла лога
        max-file: "5"

  # Настройка для балансировки запросов к kinaba
  web-proxy-kibana:
    image: nginx:latest
    container_name: nginx-proxy-kibana
    hostname: nginx-proxy-kibana
    restart: unless-stopped
    ports:
      - ${PROXY_NGINX_KIBANA_PORT}:80
    volumes:
      - ./nginx/nginx-kibana/kibana.conf:/etc/nginx/templates/default.conf.template
    networks:
      - elastic
    depends_on:
      - elastic-kibana-node-1
      - elastic-kibana-node-2
    healthcheck:
      test: curl -sS localhost:80 || exit 1
      interval: 5s
      timeout: 5s
      retries: 20
    logging:
      driver: "json-file"
      options:
        max-size: "100m" # Максимальный размер файла лога
        max-file: "5"

  # Настройка для Logstash (server 1)
  elastic-logstash-node-1:
    build:
      context: logstash/
      # Имя докерфайла из которого будет собран образ
      dockerfile: Dockerfile
    container_name: logstash-one
    hostname: logstash-one
    restart: unless-stopped
    networks:
      - elastic
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:9600/" ]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # Настройка для Logstash (server 2)
  elastic-logstash-node-2:
    build:
      context: logstash/
      # Имя докерфайла из которого будет собран образ
      dockerfile: Dockerfile
    container_name: logstash-two
    hostname: logstash-two
    restart: unless-stopped
    networks:
      - elastic
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:9600/" ]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # Настройка kibana node 1
  elastic-kibana-node-1:
    build:
      context: kibana/
      # Имя докерфайла из которого будет собран образ
      dockerfile: Dockerfile
    container_name: kibana-one
    hostname: kibana-one
    restart: unless-stopped
    environment:
      - SECURITY=true
    networks:
      - elastic
    depends_on:
      - elastic-node-1
      - elastic-node-2
      - elastic-node-3
      - elastic-node-4
    healthcheck:
      test: curl -sS localhost:5601 || exit 1
      interval: 5s
      timeout: 5s
      retries: 20
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # Настройка kibana node 1
  elastic-kibana-node-2:
    build:
      context: kibana/
      # Имя докерфайла из которого будет собран образ
      dockerfile: Dockerfile
    container_name: kibana-two
    hostname: kibana-two
    restart: unless-stopped
    environment:
      - SECURITY=true
    networks:
      - elastic
    depends_on:
      - elastic-node-1
      - elastic-node-2
      - elastic-node-3
      - elastic-node-4
    healthcheck:
      test: curl -sS localhost:5601 || exit 1
      interval: 5s
      timeout: 5s
      retries: 20
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # Настройка Elasticsearch
  elastic-node-1:
    build:
      context: elastic-node-1/
      # Имя докерфайла из которого будет собран образ
      dockerfile: Dockerfile
    container_name: elastic-node-1
    hostname: elastic-node-1
    restart: unless-stopped
    # Без этого не работает при дериктиве bootstrap.memory_lock=true
    ulimits:
      memlock:
        soft: -1
        hard: -1
    environment:
      # Отключить использование файла подкачки. Для elastic не рекомендоуется использовать swapp
      - bootstrap.memory_lock=true
      # Для одиночного хоста, не в cluster
      # - discovery.type=single-node
      - TZ=${TZ}
      # Ограничение размера кучи
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
      # Включаем настройку безопасности с применением сертификатов. Для получения корневого сертификата
      # необходимо запустить скрипт init-ca-cert.sh в папке start/
      - SECURITY=true
    volumes:
      - elastic1-data:/usr/share/elasticsearch/data/
      - ./ca-stack-cluster/:/usr/share/elasticsearch/config/cert/
    networks:
      - elastic
    depends_on:
      - elastic-node-2
    healthcheck:
      test: curl -sS localhost:9200 || exit 1
      interval: 5s
      timeout: 5s
      retries: 20
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  elastic-node-2:
    build:
      context: elastic-node-2/
      # Имя докерфайла из которого будет собран образ
      dockerfile: Dockerfile
    container_name: elastic-node-2
    hostname: elastic-node-2
    restart: unless-stopped
    # Без этого не работает при дериктиве bootstrap.memory_lock=true
    ulimits:
      memlock:
        soft: -1
        hard: -1
    environment:
      # Отключить использование файла подкачки. Для elastic не рекомендоуется использовать swapp
      - bootstrap.memory_lock=true
      # Для одиночного хоста, не в cluster
      # - discovery.type=single-node
      - TZ=${TZ}
      # Ограничение размера кучи
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
      # Включаем настройку безопасности с применением сертификатов. Для получения корневого сертификата
      # необходимо запустить скрипт init-ca-cert.sh в папке start/
      - SECURITY=true
    volumes:
      - elastic2-data:/usr/share/elasticsearch/data/
      - ./ca-stack-cluster/:/usr/share/elasticsearch/config/cert/
    networks:
      - elastic
    depends_on:
      - elastic-node-3
    healthcheck:
      test: curl -sS localhost:9200 || exit 1
      interval: 5s
      timeout: 5s
      retries: 20
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  elastic-node-3:
    build:
      context: elastic-node-3/
      # Имя докерфайла из которого будет собран образ
      dockerfile: Dockerfile
    container_name: elastic-node-3
    hostname: elastic-node-3
    restart: unless-stopped
    # Без этого не работает при дериктиве bootstrap.memory_lock=true
    ulimits:
      memlock:
        soft: -1
        hard: -1
    environment:
      # Отключить использование файла подкачки. Для elastic не рекомендоуется использовать swapp
      - bootstrap.memory_lock=true
      # Для одиночного хоста, не в cluster
      # - discovery.type=single-node
      - TZ=${TZ}
      # Ограничение размера кучи
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
      # Включаем настройку безопасности с применением сертификатов. Для получения корневого сертификата
      # необходимо запустить скрипт init-ca-cert.sh в папке start/
      - SECURITY=true
    volumes:
      - elastic3-data:/usr/share/elasticsearch/data/
      - ./ca-stack-cluster/:/usr/share/elasticsearch/config/cert/
    networks:
      - elastic
    depends_on:
      - elastic-node-4
    healthcheck:
      test: curl -sS localhost:9200 || exit 1
      interval: 5s
      timeout: 5s
      retries: 20
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  elastic-node-4:
    build:
      context: elastic-node-4/
      # Имя докерфайла из которого будет собран образ
      dockerfile: Dockerfile
    container_name: elastic-node-4
    hostname: elastic-node-4
    restart: unless-stopped
    # Без этого не работает при дериктиве bootstrap.memory_lock=true
    ulimits:
      memlock:
        soft: -1
        hard: -1
    environment:
      # Отключить использование файла подкачки. Для elastic не рекомендоуется использовать swapp
      - bootstrap.memory_lock=true
      # Для одиночного хоста, не в cluster
      # - discovery.type=single-node
      - TZ=${TZ}
      # Ограничение размера кучи
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
      # Включаем настройку безопасности с применением сертификатов. Для получения корневого сертификата
      # необходимо запустить скрипт init-ca-cert.sh в папке start/
      - SECURITY=true
    volumes:
      - elastic4-data:/usr/share/elasticsearch/data/
      - ./ca-stack-cluster/:/usr/share/elasticsearch/config/cert/
    networks:
      - elastic
    healthcheck:
      test: curl -sS localhost:9200 || exit 1
      interval: 5s
      timeout: 5s
      retries: 20
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # Две ноды elastic будет использовать в качестве балансировки нагрузки. Они будут не мастер и не дата. Только распределяют запросы и учавствуют в выборах мастера
  elastic-node-coordination-1:
    build:
      context: elastic-coordination-1/
      # Имя докерфайла из которого будет собран образ
      dockerfile: Dockerfile
    container_name: elastic-node-coordination-1
    hostname: elastic-node-coordination-1
    restart: unless-stopped
    # Без этого не работает при дериктиве bootstrap.memory_lock=true
    ulimits:
      memlock:
        soft: -1
        hard: -1
    environment:
      # Отключить использование файла подкачки. Для elastic не рекомендоуется использовать swapp
      - bootstrap.memory_lock=true
      # Для одиночного хоста, не в cluster
      # - discovery.type=single-node
      - TZ=${TZ}
      # Ограничение размера кучи
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
      # Включаем настройку безопасности с применением сертификатов. Для получения корневого сертификата
      # необходимо запустить скрипт init-ca-cert.sh в папке start/
      - SECURITY=true
    volumes:
      - ./ca-stack-cluster/:/usr/share/elasticsearch/config/cert/
    networks:
      - elastic
    depends_on:
      - elastic-node-1
      - elastic-node-2
      - elastic-node-3
      - elastic-node-4
    healthcheck:
      test: curl -sS localhost:9200 || exit 1
      interval: 5s
      timeout: 5s
      retries: 20
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  elastic-node-coordination-2:
    build:
      context: elastic-coordination-2/
      # Имя докерфайла из которого будет собран образ
      dockerfile: Dockerfile
    container_name: elastic-node-coordination-2
    hostname: elastic-node-coordination-2
    restart: unless-stopped
    # Без этого не работает при дериктиве bootstrap.memory_lock=true
    ulimits:
      memlock:
        soft: -1
        hard: -1
    environment:
      # Отключить использование файла подкачки. Для elastic не рекомендоуется использовать swapp
      - bootstrap.memory_lock=true
      # Для одиночного хоста, не в cluster
      # - discovery.type=single-node
      - TZ=${TZ}
      # Ограничение размера кучи
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
      # Включаем настройку безопасности с применением сертификатов. Для получения корневого сертификата
      # необходимо запустить скрипт init-ca-cert.sh в папке start/
      - SECURITY=true
    volumes:
      - ./ca-stack-cluster/:/usr/share/elasticsearch/config/cert/
    networks:
      - elastic
    depends_on:
      - elastic-node-1
      - elastic-node-2
      - elastic-node-3
      - elastic-node-4
    healthcheck:
      test: curl -sS localhost:9200 || exit 1
      interval: 5s
      timeout: 5s
      retries: 20
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  cerebro:
    image: lmenezes/cerebro:latest
    container_name: cerebro-elastic
    hostname: cerebro-elastic
    restart: unless-stopped
    ports:
      - ${CEREBRO_PORT}:9000
    networks:
      - elastic
    volumes:
      - ./cerebro/application.conf:/opt/cerebro/conf/application.conf
    depends_on:
      - elastic-node-1
      - elastic-node-2
      - elastic-node-3
      - elastic-node-4
      - elastic-node-coordination-1
      - elastic-node-coordination-2
    healthcheck:
      test: wget --no-verbose --tries=3 --spider localhost:9000 || exit 1
      interval: 5s
      timeout: 5s
      retries: 5
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # Для файлов логов
  filebeat:
    image: docker.elastic.co/beats/filebeat:8.11.0
    container_name: filebeat
    hostname: filebeat
    restart: unless-stopped
    volumes:
      # Конфигурация Filebeat
      - ./filebeat/filebeat.yml:/usr/share/filebeat/filebeat.yml:ro
      # Директории с конфигами
      - ./filebeat/inputs.d/:/usr/share/filebeat/inputs.d/:ro
      # - ./filebeat/outputs.d/:/usr/share/filebeat/outputs.d/:ro
      # - ./filebeat/processors.d/:/usr/share/filebeat/processors.d/:ro
      # - ./filebeat/config.d/:/usr/share/filebeat/config.d/:ro
      
      # Монтируем ВСЮ папку logs
      - ./logs:/var/log/host_logs:ro
      
      # Docker контейнеры лог (опционально)
      - /var/lib/docker/containers:/var/lib/docker/containers:ro
      - /var/run/docker.sock:/var/run/docker.sock:ro
    networks:
      - elastic
    depends_on:
      - elastic-logstash-node-1
      - elastic-logstash-node-2
    healthcheck:
      test: filebeat test config || exit 1
      interval: 10s
      timeout: 5s
      retries: 3
    # Увеличиваем лимиты на количество открытых файлов
    ulimits:
      nofile:
        soft: 65536
        hard: 65536
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
  
  # Ротация логов с помощью logrotate
  logrotate:
    image: alpine:latest
    container_name: logrotate
    restart: unless-stopped
    volumes:
      # Монтируем папку с логами
      - ./logs:/logs:rw
      # Конфигурация logrotate (опционально)
      # Пока не используется так как конфиг создается динамически в entrypoint.sh
      # - ./logrotate/config:/etc/logrotate.d:rw
      # Entrypoint скрипт
      - ./logrotate/scripts/entrypoint.sh:/entrypoint.sh:ro
    environment:
      # Частота запуска cron (по умолчанию ежедневно в 2:00)
      - CRON_SCHEDULE=* * * * *
      # Принудительный запуск при старте
      - RUN_AT_STARTUP=true
      # Максимальный размер файла для ротации
      - MAXSIZE=1M
      # Количество хранимых версий
      - ROTATE_COUNT=3
      # КОличество дней хранения файлов архивов логов
      - MAXAGE=5
    # Используем entrypoint скрипт
    entrypoint: ["/bin/sh", "/entrypoint.sh"]
    healthcheck:
      test: ["CMD", "pgrep", "crond"]
      interval: 30s
      timeout: 5s
      retries: 3
      start_period: 10s
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # Для очистки логов
  # ЗАПУСК
  # Запуск с параметрами по умолчанию
  # docker compose run --rm log-cleaner
  # Без очистки архивов
  #docker compose run --rm -e DELETE_ARCHIVES=true log-cleaner
  # Только показ что будет сделано (dry-run)
  #docker compose run --rm -e CLEAR_LOGS=false log-cleaner
  log-cleaner:
    image: alpine:latest
    container_name: log-cleaner
    restart: "no"  # Только по ручному запуску
    volumes:
      # Монтируем папку с логами
      - ./logs:/logs:rw
      # Монтируем скрипты
      - ./log-cleaner/scripts:/scripts:ro
    environment:
      # Параметры по умолчанию
      - CLEAR_LOGS=true
      - DELETE_ARCHIVES=false
    # Используем entrypoint скрипт
    entrypoint: ["/scripts/entrypoint.sh"]